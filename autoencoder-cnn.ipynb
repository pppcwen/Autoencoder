{"metadata":{"kernelspec":{"display_name":"pytorch","language":"python","name":"pytorch"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"colab":{"provenance":[],"gpuType":"T4","include_colab_link":true},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/pppcwen/Autoencoder/blob/main/Autoencoder_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github"}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nimport matplotlib.pyplot as plt","metadata":{"id":"canadian-canyon","execution":{"iopub.status.busy":"2023-09-08T07:46:45.337638Z","iopub.execute_input":"2023-09-08T07:46:45.338139Z","iopub.status.idle":"2023-09-08T07:46:45.345619Z","shell.execute_reply.started":"2023-09-08T07:46:45.338064Z","shell.execute_reply":"2023-09-08T07:46:45.344276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.5), (0.5))\n    ])\n\ntransform = transforms.ToTensor()\n\nmnist_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n\ndata_loader = torch.utils.data.DataLoader(dataset=mnist_data,\n                                          batch_size=64,\n                                          shuffle=True)","metadata":{"id":"gentle-metallic","execution":{"iopub.status.busy":"2023-09-08T07:46:45.348143Z","iopub.execute_input":"2023-09-08T07:46:45.348691Z","iopub.status.idle":"2023-09-08T07:46:45.443364Z","shell.execute_reply.started":"2023-09-08T07:46:45.348644Z","shell.execute_reply":"2023-09-08T07:46:45.442184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataiter = iter(data_loader)\nimages, labels = next(dataiter)\nprint(torch.min(images), torch.max(images))","metadata":{"id":"purple-birth","outputId":"a0dc0b76-59aa-49c2-9447-6b8ab35efcaa","execution":{"iopub.status.busy":"2023-09-08T07:46:45.446317Z","iopub.execute_input":"2023-09-08T07:46:45.446868Z","iopub.status.idle":"2023-09-08T07:46:45.475574Z","shell.execute_reply.started":"2023-09-08T07:46:45.446824Z","shell.execute_reply":"2023-09-08T07:46:45.474297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Autoencoder(nn.Module):\n    def __init__(self):\n        super().__init__()\n        # N, 1, 28, 28\n        self.encoder = nn.Sequential(\n            nn.Conv2d(1, 32, 3, stride=2, padding=1), # -> N, 16, 14, 14\n            nn.ReLU()\n        )\n        self.encoder2 = nn.Sequential(\n            nn.ReLU(),\n            nn.Conv2d(32, 64, 3) # -> N, 64, 1, 1\n        )\n        # N , 64, 1, 1\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(64, 32, 3), # -> N, 32, 7, 7\n            nn.ReLU()\n        )\n        self.decoder2 = nn.Sequential(\n            nn.ReLU(),\n            nn.ConvTranspose2d(32, 1, 3, stride=2, padding=1,output_padding=1), # N, 1, 28, 28  (N,1,27,27)\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        pool = nn.MaxPool2d(2, stride=2, return_indices=True)\n        unpool = nn.MaxUnpool2d(2, stride=2)\n        \n        \n        encoded_1 = self.encoder(x)\n        pool_output, indices = pool(encoded_1)\n        encoded = self.encoder2(pool_output)\n        decoded_1 = self.decoder(encoded)\n        unPool_output = unpool(decoded_1, indices)\n        decoded = self.decoder2(unPool_output)\n\n        return decoded\n\n\n# Note: nn.MaxPool2d -> use nn.MaxUnpool2d, or use different kernelsize, stride etc to compensate...\n# Input [-1, +1] -> use nn.Tanh","metadata":{"id":"swedish-robin","execution":{"iopub.status.busy":"2023-09-08T07:46:45.477337Z","iopub.execute_input":"2023-09-08T07:46:45.477839Z","iopub.status.idle":"2023-09-08T07:46:45.490672Z","shell.execute_reply.started":"2023-09-08T07:46:45.477784Z","shell.execute_reply":"2023-09-08T07:46:45.489447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Autoencoder()\n\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(),lr=1e-3,weight_decay=1e-6)","metadata":{"id":"educated-meditation","execution":{"iopub.status.busy":"2023-09-08T07:46:45.493553Z","iopub.execute_input":"2023-09-08T07:46:45.493981Z","iopub.status.idle":"2023-09-08T07:46:45.514448Z","shell.execute_reply.started":"2023-09-08T07:46:45.493945Z","shell.execute_reply":"2023-09-08T07:46:45.513346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Point to training loop video\nnum_epochs = 20\noutputs = []\nfor epoch in range(num_epochs):\n    for (img, _) in data_loader:\n        recon = model(img)\n        loss = criterion(recon, img)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    print(f'Epoch:{epoch+1}, Loss:{loss.item():.4f}')\n    outputs.append((epoch, img, recon))","metadata":{"id":"steady-ceremony","outputId":"58780d93-abb7-487d-987a-6f5c24907008","execution":{"iopub.status.busy":"2023-09-08T07:46:45.516008Z","iopub.execute_input":"2023-09-08T07:46:45.516389Z","iopub.status.idle":"2023-09-08T08:01:26.427180Z","shell.execute_reply.started":"2023-09-08T07:46:45.516359Z","shell.execute_reply":"2023-09-08T08:01:26.425921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for k in range(0, num_epochs, 4):\n    plt.figure(figsize=(9, 2))\n    plt.gray()\n    imgs = outputs[k][1].detach().numpy()\n    recon = outputs[k][2].detach().numpy()\n    for i, item in enumerate(imgs):\n        if i >= 9: break\n        plt.subplot(2, 9, i+1)\n        # item: 1, 28, 28\n        plt.imshow(item[0])\n\n    for i, item in enumerate(recon):\n        if i >= 9: break\n        plt.subplot(2, 9, 9+i+1) # row_length + i + 1\n        # item: 1, 28, 28\n        plt.imshow(item[0])","metadata":{"id":"numerous-greensboro","outputId":"2912bad3-77f7-446f-ff51-c23d4859d292","execution":{"iopub.status.busy":"2023-09-08T08:01:26.428571Z","iopub.execute_input":"2023-09-08T08:01:26.428924Z","iopub.status.idle":"2023-09-08T08:01:38.681042Z","shell.execute_reply.started":"2023-09-08T08:01:26.428893Z","shell.execute_reply":"2023-09-08T08:01:38.679678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Homework: Use MaxPool2d, inspect the encoded data (can it be plotted as img?)","metadata":{"id":"coastal-cement","execution":{"iopub.status.busy":"2023-09-08T08:01:38.682769Z","iopub.execute_input":"2023-09-08T08:01:38.683389Z","iopub.status.idle":"2023-09-08T08:01:38.688769Z","shell.execute_reply.started":"2023-09-08T08:01:38.683353Z","shell.execute_reply":"2023-09-08T08:01:38.687468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"diverse-hours"},"execution_count":null,"outputs":[]}]}